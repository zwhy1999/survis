@article{app13116355,
 AUTHOR = {Yang, Jing and Chen, Yen-Lin and Por, Lip Yee and Ku, Chin Soon},
 TITLE = {A Systematic Literature Review of Information Security in Chatbots},
 JOURNAL = {Applied Sciences},
 VOLUME = {13},
 YEAR = {2023},
 NUMBER = {11},
 ARTICLE-NUMBER = {6355},
 URL = {https://www.mdpi.com/2076-3417/13/11/6355},
 ISSN = {2076-3417},
 ABSTRACT = {Chatbots have become increasingly popular in recent years, but they also present security risks and vulnerabilities that need to be addressed. This systematic literature review examines the existing research relating to information security in chatbots, identifying the potential threats, proposed solutions, and future directions for research. The review finds that chatbots face various security threats, including malicious input, user profiling, contextual attacks, and data breaches, and that solutions such as blockchain technology, end-to-end encryption, and organizational controls can be used to mitigate these concerns. The review also highlights the importance of maintaining user trust and addressing privacy concerns for the successful adoption and continued use of chatbots. A taxonomy developed in this review provides a useful framework for categorizing the articles and their findings. The review concludes by identifying future research directions that include developing more sophisticated authentication and authorization mechanisms, exploring the use of privacy-enhancing technologies, and improving the detection and prevention of security threats, among others. This review contributes to the growing body of literature on information security in chatbots and can guide future research and practice in this field.},
 DOI = {10.3390/app13116355}
}

@inproceedings{xu-etal-2020-personal,
    title = "Personal Information Leakage Detection in Conversations",
    author = "Xu, Qiongkai  and
      Qu, Lizhen  and
      Gao, Zeyu  and
      Haffari, Gholamreza",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.532",
    doi = "10.18653/v1/2020.emnlp-main.532",
    pages = "6567--6580",
    abstract = "The global market size of conversational assistants (chatbots) is expected to grow to USD 9.4 billion by 2024, according to MarketsandMarkets. Despite the wide use of chatbots, leakage of personal information through chatbots poses serious privacy concerns for their users. In this work, we propose to protect personal information by warning users of detected suspicious sentences generated by conversational assistants. The detection task is formulated as an alignment optimization problem and a new dataset PERSONA-LEAKAGE is collected for evaluation. In this paper, we propose two novel constrained alignment models, which consistently outperform baseline methods on Moreover, we conduct analysis on the behavior of recently proposed personalized chit-chat dialogue systems. The empirical results show that those systems suffer more from personal information disclosure than the widely used Seq2Seq model and the language model. In those cases, a significant number of information leaking utterances can be detected by our models with high precision.",
}

@inproceedings{M2017,
   abstract = {Nowadays, businesses are slowly starting to deploy mobile messenger chatbots as a new method of communication with its customers. Due to the subject?s infancy and lack of research on the subject, the purpose of this study is to explore the concept of mobile messenger chatbots and an attempt is made to determine the Dutch Millennials? intention to use messenger chatbots as the next interface for mobile commerce. A research model is proposed based on the Technology Acceptance Model (TAM) and Innovation Diffusion Theory (IDT). Data is collected by means of an online survey among 195 participants. The proposed research model is tested by means of simple regression analysis and results are cross-validated using IBM Watson Analytics. All proposed hypotheses are supported. However, there is no unambiguous answer to whether Dutch Millennials have the intention to use mobile messenger chatbots as the next interface for commerce. Nonetheless, more than half of the respondents express a positive first impression towards mobile messenger chatbots. This study knows some limitations regarding external validity and the research model is limited to five independent constructs. Additional constructs or measurement tools could be used to obtain a deeper understanding regarding the subject. Moreover, using a real-life experiment may generate distinctive results. Organizations wanting to deploy messenger chatbots, marketers and chatbot developers should consider compatibility, the consumers? lifestyle and shopping preferences, for a successful implementation. Similarly, the consumers? privacy concerns and resistance to intrusive mobile advertisement are important topics to be considered.},
   author = {M. van {Eeuwen}},
   month = {11},
   url = {http://essay.utwente.nl/71706/},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Mobile conversational commerce: messenger chatbots as the next interface between businesses and consumers},
   year = {2017},
}        

@inproceedings{belen2021privacy,
   abstract = {Through advances in their conversational abilities, chatbots have started to request and process an increasing variety of sensitive personal information. The accurate disclosure of sensitive information is essential where it is used to provide advice and support to users in the healthcare and finance sectors. In this study, we explore users’ concerns regarding factors associated with the use of sensitive data by chatbot providers. We surveyed a representative sample of 491 British citizens. Our results show that the user concerns focus on deleting personal information and concerns about their data’s inappropriate use. We also identified that individuals were concerned about losing control over their data after a conversation with conversational agents. We found no effect from a user’s gender or education but did find an effect from the user’s age, with those over 45 being more concerned than those under 45. We also considered the factors that engender trust in a chatbot. Our respondents’ primary focus was on the chatbot’s technical elements, with factors such as the response quality being identified as the most critical factor. We again found no effect from the user’s gender or education level; however, when we considered some social factors (e.g. avatars or perceived ‘friendliness’), we found those under 45 years old rated these as more important than those over 45. The paper concludes with a discussion of these results within the context of designing inclusive, digital systems that support a wide range of users.},
   author = {Rahime Belen Saglam and Jason R.C. Nurse and Duncan Hodges},
   doi = {10.1007/978-3-030-78642-7_53},
   isbn = {9783030786410},
   issn = {18650937},
   journal = {Communications in Computer and Information Science},
   keywords = {Artificial intelligence,Chatbots,Conversational agents,Data privacy,Human factors,Personal information,Trust},
   pages = {391-399},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Privacy Concerns in Chatbot Interactions: When to Trust and When to Worry},
   volume = {1420},
   year = {2021},
}

@article{bouhia2022drivers,
  title={Drivers of privacy concerns when interacting with a chatbot in a customer service encounter},
  author={Bouhia, Mariem and Rajaobelina, Lova and PromTep, Sandrine and Arcand, Manon and Ricard, Line},
  journal={International Journal of Bank Marketing},
  volume={40},
  number={6},
  pages={1159--1181},
  year={2022},
  publisher={Emerald Publishing Limited}
}

@article{https://doi.org/10.1002/cpe.6426,
author = {Hasal, Martin and Nowaková, Jana and Ahmed Saghair, Khalifa and Abdulla, Hussam and Snášel, Václav and Ogiela, Lidia},
title = {Chatbots: Security, privacy, data protection, and social aspects},
journal = {Concurrency and Computation: Practice and Experience},
volume = {33},
number = {19},
pages = {e6426},
keywords = {chat, chatbots, data protection, GDPR, security, virtual assistants},
doi = {https://doi.org/10.1002/cpe.6426},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6426},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.6426},
abstract = {Summary Chatbots are artificial communication systems becoming increasingly popular and not all their security questions are clearly solved. People use chatbots for assistance in shopping, bank communication, meal delivery, healthcare, cars, and many other actions. However, it brings an additional security risk and creates serious security challenges which have to be handled. Understanding the underlying problems requires defining the crucial steps in the techniques used to design chatbots related to security. There are many factors increasing security threats and vulnerabilities. All of them are comprehensively studied, and security practices to decrease security weaknesses are presented. Modern chatbots are no longer rule-based models, but they employ modern natural language and machine learning techniques. Such techniques learn from a conversation, which can contain personal information. The paper discusses circumstances under which such data can be used and how chatbots treat them. Many chatbots operate on a social/messaging platform, which has their terms and conditions about data. The paper aims to present a comprehensive study of security aspects in communication with chatbots. The article could open a discussion and highlight the problems of data storage and usage obtained from the communication user—chatbot and propose some standards to protect the user.},
year = {2021}
}

@article{lappeman2023trust,
  title={Trust and digital privacy: willingness to disclose personal information to banking chatbot services},
  author={Lappeman, James and Marlie, Siddeeqah and Johnson, Tamryn and Poggenpoel, Sloane},
  journal={Journal of Financial Services Marketing},
  volume={28},
  number={2},
  pages={337--357},
  year={2023},
  publisher={Springer}
}

@article{mani2017drivers,
  title={Drivers of consumers’ resistance to smart products},
  author={Mani, Zied and Chouk, In{\`e}s},
  journal={Journal of Marketing Management},
  volume={33},
  number={1-2},
  pages={76--97},
  year={2017},
  publisher={Taylor \& Francis}
}

@Article{electronics11234016,
AUTHOR = {Voege, Peter and Abu Sulayman, Iman I. M. and Ouda, Abdelkader},
TITLE = {Smart Chatbot for User Authentication},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {23},
ARTICLE-NUMBER = {4016},
URL = {https://www.mdpi.com/2079-9292/11/23/4016},
ISSN = {2079-9292},
ABSTRACT = {Despite being the most widely used authentication mechanism, password-based authentication is not very secure, being easily guessed or brute-forced. To address this, many systems which especially value security adopt Multi-Factor Authentication (MFA), in which multiple different authentication mechanisms are used concurrently. JitHDA (Just-in-time human dynamics based authentication engine) is a new authentication mechanism which can add another option to MFA capabilities. JitHDA observes human behaviour and human dynamics to gather up to date information on the user from which authentication questions can be dynamically generated. This paper proposes a system that implements JitHDA, which we call Autonomous Inquiry-based Authentication Chatbot (AIAC). AIAC uses anomalous events gathered from a user’s recent activity to create personalized questions for the user to answer, and is designed to improve its own capabilities over time using neural networks trained on data gathered during authentication sessions. Due to using the user’s recent activity, they will be easy for the authentic user to answer and hard for a fraudulent user to guess, and as the user’s recent history updates between authentication sessions new questions will be dynamically generated to replace old ones. We intend to show in this paper that AIAC is a viable implementation of JitHDA.},
DOI = {10.3390/electronics11234016}
}

@INPROCEEDINGS{9355740,
  author={Ye, Winson and Li, Qun},
  booktitle={2020 IEEE/ACM Symposium on Edge Computing (SEC)}, 
  title={Chatbot Security and Privacy in the Age of Personal Assistants}, 
  year={2020},
  volume={},
  number={},
  pages={388-393},
  keywords={Privacy;Computer architecture;Chatbot;Security;Standards;Next generation networking;Edge computing;dialogue system;chatbot;personal assistants;conversational response generation;conversational AI;chatbot security;NLP security;adversarial text generation;IoT security},
  doi={10.1109/SEC50012.2020.00057}}
